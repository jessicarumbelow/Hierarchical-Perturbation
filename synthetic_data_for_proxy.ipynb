{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNl8yRGBaQYS",
        "outputId": "23246197-6914-40a2-bc2c-58e737edea0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchray in /usr/local/lib/python3.10/dist-packages (1.0.0.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from torchray) (6.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torchray) (3.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchray) (23.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchray) (2.0.7)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (from torchray) (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchray) (2.31.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from torchray) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from torchray) (0.16.0+cu121)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.0->torchray) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchray) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchray) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchray) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (2.1.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo->torchray) (2.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchray) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchray) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-42-b47c16aaab07>:13: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import gaussian_filter\n"
          ]
        }
      ],
      "source": [
        "!pip install torchray wandb\n",
        "\n",
        "import os\n",
        "import wandb\n",
        "import torch\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "from torchray.attribution.rise import rise\n",
        "from torchray.benchmark.datasets import get_dataset, coco_as_mask, voc_as_mask\n",
        "from torchray.utils import imsc, get_device, xmkdir\n",
        "import torchray.attribution.extremal_perturbation as elp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWVFa47JvQtd",
        "outputId": "28baac55-7694-4645-91fc-1ddc8f1711c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-55-af4adf69124b>:6: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import gaussian_filter\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchray.utils import imsc\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def gkern(klen, nsig):\n",
        "\t\"\"\"Returns a Gaussian kernel array.\n",
        "\tConvolution with it results in image blurring.\"\"\"\n",
        "\t# create nxn zeros\n",
        "\tinp = np.zeros((klen, klen))\n",
        "\t# set element at the middle to one, a dirac delta\n",
        "\tinp[klen // 2, klen // 2] = 1\n",
        "\t# gaussian-smooth the dirac, resulting in a gaussian filter mask\n",
        "\tk = gaussian_filter(inp, nsig)\n",
        "\tkern = np.zeros((3, 3, klen, klen))\n",
        "\tkern[0, 0] = k\n",
        "\tkern[1, 1] = k\n",
        "\tkern[2, 2] = k\n",
        "\treturn torch.from_numpy(kern.astype('float32'))\n",
        "\n",
        "\n",
        "def blur(x, klen=11, ksig=5):\n",
        "\tkern = gkern(klen, ksig)\n",
        "\treturn F.conv2d(x, kern, padding=klen // 2)\n",
        "\n",
        "\n",
        "def normalise(x):\n",
        "\treturn (x - x.min()) / max(x.max() - x.min(), 0.0001)\n",
        "\n",
        "\n",
        "def hierarchical_perturbation(model,\n",
        "\t\t\t\t\t\t\t  input,\n",
        "\t\t\t\t\t\t\t  target,\n",
        "\t\t\t\t\t\t\t  vis=False,\n",
        "\t\t\t\t\t\t\t  interp_mode='nearest',\n",
        "\t\t\t\t\t\t\t  resize=None,\n",
        "\t\t\t\t\t\t\t  batch_size=32,\n",
        "\t\t\t\t\t\t\t  perturbation_type='mean', threshold_mode='mid-range', return_info=False):\n",
        "\tprint('\\nBelieve the HiPe!')\n",
        "\twith torch.no_grad():\n",
        "\n",
        "\t\tdev = input.device\n",
        "\t\tbn, channels, input_y_dim, input_x_dim = input.shape\n",
        "\t\tdim = min(input_x_dim, input_y_dim)\n",
        "\t\ttotal_masks = 0\n",
        "\t\tdepth = 0\n",
        "\t\tnum_cells = int(max(np.ceil(np.log2(dim)), 1)/2)\n",
        "\t\tprint('Num cells: {}'.format(num_cells))\n",
        "\t\tmax_depth = int(np.log2(dim / num_cells)) - 1\n",
        "\t\tprint('Max depth: {}'.format(max_depth))\n",
        "\t\tsaliency = torch.zeros((1, 1, input_y_dim, input_x_dim), device=dev)\n",
        "\t\tmax_batch = batch_size\n",
        "\n",
        "\t\tthresholds_d_list = []\n",
        "\t\tmasks_d_list = []\n",
        "\n",
        "\t\toutput = model(input)[:, target]\n",
        "\n",
        "\t\tif perturbation_type == 'blur':\n",
        "\t\t\tpre_b_image = blur(input.clone().cpu()).to(dev)\n",
        "\n",
        "\t\twhile (num_cells*2) <= (dim/4):\n",
        "\n",
        "\t\t\tmasks_list = []\n",
        "\t\t\tb_list = []\n",
        "\t\t\tnum_cells *= 2\n",
        "\t\t\tdepth += 1\n",
        "\t\t\tif threshold_mode == 'mean':\n",
        "\t\t\t\tthreshold = torch.mean(saliency)\n",
        "\t\t\telse:\n",
        "\t\t\t\tthreshold = torch.min(saliency) + ((torch.max(saliency) - torch.min(saliency)) / 2)\n",
        "\n",
        "\t\t\tthresholds_d_list.append(threshold.item())\n",
        "\n",
        "\t\t\ty_ixs = range(-1, num_cells)\n",
        "\t\t\tx_ixs = range(-1, num_cells)\n",
        "\t\t\tx_cell_dim = input_x_dim // num_cells\n",
        "\t\t\ty_cell_dim = input_y_dim // num_cells\n",
        "\n",
        "\t\t\tprint('Depth: {}, {} x {} Cell Dim'.format(depth, y_cell_dim, x_cell_dim))\n",
        "\t\t\tprint('Threshold: {}'.format(threshold))\n",
        "\t\t\tprint('Range {:.1f} to {:.1f}'.format(saliency.min(), saliency.max()))\n",
        "\n",
        "\t\t\tfor x in x_ixs:\n",
        "\t\t\t\tfor y in y_ixs:\n",
        "\t\t\t\t\tx1, y1 = max(0, x), max(0, y)\n",
        "\t\t\t\t\tx2, y2 = min(x + 2, num_cells), min(y + 2, num_cells)\n",
        "\n",
        "\t\t\t\t\tmask = torch.zeros((1, 1, num_cells, num_cells), device=dev)\n",
        "\t\t\t\t\tmask[:, :, y1:y2, x1:x2] = 1.0\n",
        "\t\t\t\t\tlocal_saliency = F.interpolate(mask, (input_y_dim, input_x_dim), mode=interp_mode) * saliency\n",
        "\n",
        "\t\t\t\t\tif depth > 1:\n",
        "\t\t\t\t\t\tlocal_saliency = torch.max(local_saliency)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tlocal_saliency = 0\n",
        "\n",
        "\t\t\t\t\t# If salience of region is greater than the average, generate higher resolution mask\n",
        "\t\t\t\t\tif local_saliency >= threshold:\n",
        "\n",
        "\t\t\t\t\t\tmasks_list.append(abs(mask - 1))\n",
        "\n",
        "\t\t\t\t\t\tif perturbation_type == 'blur':\n",
        "\n",
        "\t\t\t\t\t\t\tb_image = input.clone()\n",
        "\t\t\t\t\t\t\tb_image[:, :, y1 * y_cell_dim:y2 * y_cell_dim, x1 * x_cell_dim:x2 * x_cell_dim] = pre_b_image[:, :, y1 * y_cell_dim:y2 * y_cell_dim, x1 * x_cell_dim:x2 * x_cell_dim]\n",
        "\t\t\t\t\t\t\tb_list.add(b_image)\n",
        "\n",
        "\t\t\t\t\t\tif perturbation_type == 'mean':\n",
        "\t\t\t\t\t\t\tb_image = input.clone()\n",
        "\t\t\t\t\t\t\tmean = torch.mean(b_image[:, :, y1 * y_cell_dim:y2 * y_cell_dim, x1 * x_cell_dim:x2 * x_cell_dim],\n",
        "\t\t\t\t\t\t\t\t\t\t\t  axis=(-1, -2), keepdims=True)\n",
        "\n",
        "\t\t\t\t\t\t\tb_image[:, :, y1 * y_cell_dim:y2 * y_cell_dim, x1 * x_cell_dim:x2 * x_cell_dim] = mean\n",
        "\t\t\t\t\t\t\tb_list.append(b_image)\n",
        "\n",
        "\t\t\tnum_masks = len(masks_list)\n",
        "\t\t\tprint('Selected {} masks at depth {}'.format(num_masks, depth))\n",
        "\t\t\tprint('Masks: {}'.format(num_masks))\n",
        "\t\t\tif num_masks == 0:\n",
        "\t\t\t\tdepth -= 1\n",
        "\t\t\t\tbreak\n",
        "\t\t\ttotal_masks += num_masks\n",
        "\t\t\tmasks_d_list.append(num_masks)\n",
        "\n",
        "\t\t\twhile len(masks_list) > 0:\n",
        "\t\t\t\tm_ix = min(len(masks_list), max_batch)\n",
        "\t\t\t\tif perturbation_type != 'fade':\n",
        "\t\t\t\t\tb_imgs = torch.cat(b_list[:m_ix])\n",
        "\t\t\t\t\tdel b_list[:m_ix]\n",
        "\t\t\t\tmasks = torch.cat(masks_list[:m_ix])\n",
        "\t\t\t\tdel masks_list[:m_ix]\n",
        "\n",
        "\t\t\t\t# resize low-res masks to input size\n",
        "\t\t\t\tmasks = F.interpolate(masks, (input_y_dim, input_x_dim), mode=interp_mode)\n",
        "\n",
        "\t\t\t\tif perturbation_type == 'fade':\n",
        "\t\t\t\t\tperturbed_outputs = torch.relu(output - model(input * masks)[:, target])\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tperturbed_outputs = torch.relu(output - model(b_imgs)[:, target])\n",
        "\n",
        "\t\t\t\tsal = perturbed_outputs.reshape(-1,1,1,1) * torch.abs(masks - 1)\n",
        "\t\t\t\tsaliency += torch.sum(sal, dim=(0, 1))\n",
        "\n",
        "\t\t\tif vis:\n",
        "\t\t\t\tplt.figure(figsize=(8, 4))\n",
        "\t\t\t\tplt.subplot(1, 3, 1)\n",
        "\t\t\t\tplt.title('Depth: {}, Threshold: {:.1f}'.format(depth, threshold))\n",
        "\t\t\t\timsc(torch.sum(input.cpu(), dim=(0)).unsqueeze(0))\n",
        "\t\t\t\tplt.subplot(1, 3, 2)\n",
        "\t\t\t\tif perturbation_type == 'fade':\n",
        "\t\t\t\t\timsc(torch.sum(input.cpu() * masks.cpu(), dim=(0)).unsqueeze(0))\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\timsc(torch.sum(b_imgs.cpu(), dim=(0)).unsqueeze(0))\n",
        "\t\t\t\tplt.subplot(1, 3, 3)\n",
        "\t\t\t\timsc(torch.sum(saliency.cpu(), dim=(0, 1)).unsqueeze(0))\n",
        "\t\t\t\tplt.show()\n",
        "\t\t\t\tplt.figure(figsize=(8, 4))\n",
        "\t\t\t\tpd.Series(normalise(saliency).cpu().reshape(-1)).plot(label='Saliency ({})'.format(threshold_mode))\n",
        "\t\t\t\tpd.Series(normalise(input).cpu().reshape(-1)).plot(label='Actual')\n",
        "\t\t\t\tplt.legend()\n",
        "\t\t\t\tplt.show()\n",
        "\n",
        "\t\tprint('Used {} masks in total.'.format(total_masks))\n",
        "\t\tif resize is not None:\n",
        "\t\t\tsaliency = F.interpolate(saliency, (resize[1], resize[0]), mode=interp_mode)\n",
        "\t\tif return_info:\n",
        "\t\t\treturn saliency, {'thresholds': thresholds_d_list, 'masks': masks_d_list, 'total_masks': total_masks}\n",
        "\t\telse:\n",
        "\t\t\treturn saliency, total_masks\n",
        "\n",
        "\n",
        "def resize_saliency(tensor, saliency, size, mode):\n",
        "    \"\"\"Resize a saliency map.\n",
        "\n",
        "    Args:\n",
        "        tensor (:class:`torch.Tensor`): reference tensor.\n",
        "        saliency (:class:`torch.Tensor`): saliency map.\n",
        "        size (bool or tuple of int): if a tuple (i.e., (width, height),\n",
        "            resize :attr:`saliency` to :attr:`size`. If True, resize\n",
        "            :attr:`saliency: to the shape of :attr:`tensor`; otherwise,\n",
        "            return :attr:`saliency` unchanged.\n",
        "        mode (str): mode for :func:`torch.nn.functional.interpolate`.\n",
        "\n",
        "    Returns:\n",
        "        :class:`torch.Tensor`: Resized saliency map.\n",
        "    \"\"\"\n",
        "    if size is not False:\n",
        "        if size is True:\n",
        "            size = tensor.shape[2:]\n",
        "        elif isinstance(size, tuple) or isinstance(size, list):\n",
        "            # width, height -> height, width\n",
        "            size = size[::-1]\n",
        "        else:\n",
        "            assert False, \"resize must be True, False or a tuple.\"\n",
        "        saliency = F.interpolate(\n",
        "            saliency, size, mode=mode, align_corners=False)\n",
        "    return saliency\n",
        "\n",
        "\n",
        "def _upsample_reflect(x, size, interpolate_mode=\"bilinear\"):\n",
        "    r\"\"\"Upsample 4D :class:`torch.Tensor` with reflection padding.\n",
        "\n",
        "    Args:\n",
        "        x (:class:`torch.Tensor`): 4D tensor to interpolate.\n",
        "        size (int or list or tuple of ints): target size\n",
        "        interpolate_mode (str): mode to pass to\n",
        "            :function:`torch.nn.functional.interpolate` function call\n",
        "            (default: \"bilinear\").\n",
        "\n",
        "    Returns:\n",
        "        :class:`torch.Tensor`: upsampled tensor.\n",
        "    \"\"\"\n",
        "    # Check and get input size.\n",
        "    assert len(x.shape) == 4\n",
        "    orig_size = x.shape[2:]\n",
        "\n",
        "    # Check target size.\n",
        "    if not isinstance(size, tuple) and not isinstance(size, list):\n",
        "        assert isinstance(size, int)\n",
        "        size = (size, size)\n",
        "    assert len(size) == 2\n",
        "\n",
        "    # Ensure upsampling.\n",
        "    for i, o_s in enumerate(orig_size):\n",
        "        assert o_s <= size[i]\n",
        "\n",
        "    # Get size of input cell when interpolated.\n",
        "    cell_size = [int(np.ceil(s / orig_size[i])) for i, s in enumerate(size)]\n",
        "\n",
        "    # Get size of interpolated input with padding.\n",
        "    pad_size = [int(cell_size[i] * (orig_size[i] + 2))\n",
        "                for i in range(len(orig_size))]\n",
        "\n",
        "    # Pad input with reflection padding.\n",
        "    x_padded = F.pad(x, (1, 1, 1, 1), mode=\"reflect\")\n",
        "\n",
        "    # Interpolated padded input.\n",
        "    x_up = F.interpolate(x_padded,\n",
        "                         pad_size,\n",
        "                         mode=interpolate_mode,\n",
        "                         align_corners=False)\n",
        "\n",
        "    # Slice interpolated input to size.\n",
        "    x_new = x_up[:,\n",
        "                 :,\n",
        "                 cell_size[0]:cell_size[0] + size[0],\n",
        "                 cell_size[1]:cell_size[1] + size[1]]\n",
        "\n",
        "    return x_new\n",
        "\n",
        "\n",
        "def rise(model,\n",
        "         input,\n",
        "         target=None,\n",
        "         seed=0,\n",
        "         num_masks=8000,\n",
        "         num_cells=7,\n",
        "         filter_masks=None,\n",
        "         batch_size=32,\n",
        "         p=0.5,\n",
        "         resize=False,\n",
        "         resize_mode='bilinear'):\n",
        "    r\"\"\"RISE.\n",
        "\n",
        "    Args:\n",
        "        model (:class:`torch.nn.Module`): a model.\n",
        "        input (:class:`torch.Tensor`): input tensor.\n",
        "        seed (int, optional): manual seed used to generate random numbers.\n",
        "            Default: ``0``.\n",
        "        num_masks (int, optional): number of RISE random masks to use.\n",
        "            Default: ``8000``.\n",
        "        num_cells (int, optional): number of cells for one spatial dimension\n",
        "            in low-res RISE random mask. Default: ``7``.\n",
        "        filter_masks (:class:`torch.Tensor`, optional): If given, use the\n",
        "            provided pre-computed filter masks. Default: ``None``.\n",
        "        batch_size (int, optional): batch size to use. Default: ``128``.\n",
        "        p (float, optional): with prob p, a low-res cell is set to 0;\n",
        "            otherwise, it's 1. Default: ``0.5``.\n",
        "        resize (bool or tuple of ints, optional): If True, resize saliency map\n",
        "            to size of :attr:`input`. If False, don't resize. If (width,\n",
        "            height) tuple, resize to (width, height). Default: ``False``.\n",
        "        resize_mode (str, optional): If resize is not None, use this mode for\n",
        "            the resize function. Default: ``'bilinear'``.\n",
        "\n",
        "    Returns:\n",
        "        :class:`torch.Tensor`: RISE saliency map.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # Get device of input (i.e., GPU).\n",
        "        dev = input.device\n",
        "\n",
        "        # Initialize saliency mask and mask normalization term.\n",
        "        input_shape = input.shape\n",
        "        saliency_shape = list(input_shape)\n",
        "\n",
        "        height = input_shape[2]\n",
        "        width = input_shape[3]\n",
        "\n",
        "        out = model(input)\n",
        "        num_classes = out.shape[1]\n",
        "\n",
        "        saliency_shape[1] = num_classes\n",
        "        saliency = torch.zeros(saliency_shape, device=dev)\n",
        "\n",
        "        # Number of spatial dimensions.\n",
        "        nsd = len(input.shape) - 2\n",
        "        assert nsd == 2\n",
        "\n",
        "        # Spatial size of low-res grid cell.\n",
        "        cell_size = tuple([int(np.ceil(s / num_cells))\n",
        "                           for s in input_shape[2:]])\n",
        "\n",
        "        # Spatial size of upsampled mask with buffer (input size + cell size).\n",
        "        up_size = tuple([input_shape[2 + i] + cell_size[i]\n",
        "                         for i in range(nsd)])\n",
        "\n",
        "        # Save current random number generator state.\n",
        "        state = torch.get_rng_state()\n",
        "\n",
        "        # Set seed.\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        if filter_masks is not None:\n",
        "            assert len(filter_masks) == num_masks\n",
        "\n",
        "        num_chunks = (num_masks + batch_size - 1) // batch_size\n",
        "        for chunk in range(num_chunks):\n",
        "            # Generate RISE random masks on the fly.\n",
        "            mask_bs = min(num_masks - batch_size * chunk, batch_size)\n",
        "\n",
        "            if filter_masks is None:\n",
        "                # Generate low-res, random binary masks.\n",
        "                grid = (torch.rand(mask_bs, 1, *((num_cells,) * nsd),\n",
        "                                   device=dev) < p).float()\n",
        "\n",
        "                # Upsample low-res masks to input shape + buffer.\n",
        "                masks_up = _upsample_reflect(grid, up_size)\n",
        "\n",
        "                # Save final RISE masks with random shift.\n",
        "                masks = torch.empty(mask_bs, 1, *input_shape[2:], device=dev)\n",
        "                shift_x = torch.randint(0,\n",
        "                                        cell_size[0],\n",
        "                                        (mask_bs,),\n",
        "                                        device='cpu')\n",
        "                shift_y = torch.randint(0,\n",
        "                                        cell_size[1],\n",
        "                                        (mask_bs,),\n",
        "                                        device='cpu')\n",
        "                for i in range(mask_bs):\n",
        "                    masks[i] = masks_up[i,\n",
        "                                        :,\n",
        "                                        shift_x[i]:shift_x[i] + height,\n",
        "                                        shift_y[i]:shift_y[i] + width]\n",
        "            else:\n",
        "                masks = filter_masks[\n",
        "                    chunk * batch_size:chunk * batch_size + mask_bs]\n",
        "\n",
        "            # Accumulate saliency mask.\n",
        "            for i, inp in enumerate(input):\n",
        "                out = model(inp.unsqueeze(0) * masks)\n",
        "                if len(out.shape) == 4:\n",
        "                    # TODO: Consider handling FC outputs more flexibly.\n",
        "                    assert out.shape[2] == 1\n",
        "                    assert out.shape[3] == 1\n",
        "                    out = out[:, :, 0, 0]\n",
        "                sal = torch.matmul(out.data.transpose(0, 1),\n",
        "                                   masks.view(mask_bs, height * width))\n",
        "                sal = sal.view((num_classes, height, width))\n",
        "                saliency[i] = saliency[i] + sal\n",
        "\n",
        "        # Normalize saliency mask.\n",
        "        saliency /= num_masks\n",
        "\n",
        "        # Restore original random number generator state.\n",
        "        torch.set_rng_state(state)\n",
        "\n",
        "        # Resize saliency mask if needed.\n",
        "        saliency = resize_saliency(input,\n",
        "                                   saliency,\n",
        "                                   resize,\n",
        "                                   mode=resize_mode)\n",
        "        return saliency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DxpqarI1vQFU"
      },
      "outputs": [],
      "source": [
        "class SyntheticDataset(Dataset):\n",
        "\tdef __init__(self, num_samples=1000, dim=(100, 100), min_coverage=0.1, max_coverage=0.8, max_salient_regions=10, random_sal_val=False):\n",
        "\t\tself.samples, self.salient_region_sizes, self.num_salient_regions = self.generate_synthetic(num_samples, dim, min_coverage, max_coverage, max_salient_regions, random_sal_val)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.samples)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\treturn self.samples[idx].unsqueeze(0), self.salient_region_sizes[idx], self.num_salient_regions[idx]\n",
        "\n",
        "\tdef generate_synthetic(self, num_samples, dim, min_coverage, max_coverage, max_salient_regions, random_sal_val):\n",
        "\t\tsamples = []\n",
        "\t\tsalient_region_sizes = []\n",
        "\t\tnum_salient_regions = []\n",
        "\n",
        "\t\tnum_covg = num_samples//max_salient_regions\n",
        "\n",
        "\t\t# Generate uniform distribution for coverage and number of salient regions\n",
        "\t\tcoverage_values = np.linspace(min_coverage, max_coverage, num_covg)\n",
        "\t\tsalient_region_counts = range(1,max_salient_regions+1)\n",
        "\t\tprint('coverage', coverage_values)\n",
        "\t\tprint('region counts', salient_region_counts)\n",
        "\n",
        "\t\tfor coverage in coverage_values:\n",
        "\t\t\tfor count in salient_region_counts:\n",
        "\t\t\t\tbase = torch.zeros(dim)\n",
        "\t\t\t\tregion_size_x = int(dim[0] * (coverage/count))\n",
        "\t\t\t\tregion_size_y = int(dim[1] * (coverage/count))\n",
        "\n",
        "\t\t\t\tfor region in range(count):\n",
        "\n",
        "\t\t\t\t\tstart_x, start_y = -1, -1\n",
        "\t\t\t\t\tattempts = 0\n",
        "\t\t\t\t\tmax_attempts = 10000  # Limit the number of attempts to find a non-overlapping region\n",
        "\t\t\t\t\t# Check for overlaps\n",
        "\t\t\t\t\twhile start_x < 0 or torch.sum(base[start_x:start_x + region_size_x, start_y:start_y + region_size_y]) > 0:\n",
        "\t\t\t\t\t\tstart_x = random.randint(0, dim[0] - region_size_x)\n",
        "\t\t\t\t\t\tstart_y = random.randint(0, dim[1] - region_size_y)\n",
        "\t\t\t\t\t\tattempts += 1\n",
        "\t\t\t\t\t\tif attempts >= max_attempts:\n",
        "\t\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\tbase[start_x:start_x + region_size_x, start_y:start_y + region_size_y] = 1 if not random_sal_val else min(random.random(), 0.99) + 0.01\n",
        "\t\t\t\tsamples.append(base)\n",
        "\t\t\t\tsalient_region_sizes.append(base.mean())\n",
        "\t\t\t\tnum_salient_regions.append(count)\n",
        "\n",
        "\t\treturn samples, salient_region_sizes, num_salient_regions\n",
        "\n",
        "\n",
        "class ProxyModel(torch.nn.Module):\n",
        "\n",
        "\tdef __init__(self, numel):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.linear = torch.nn.Linear(numel, 1)\n",
        "\t\tself.linear.weight=torch.nn.Parameter(torch.ones_like(self.linear.weight), requires_grad=False)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tsum = self.linear(x.reshape(x.shape[0], -1))\n",
        "\t\treturn sum\n",
        "\n",
        "\n",
        "def calculate_precision_recall_f1(ground_truth, predicted_saliency):\n",
        "\t# Epsilon may be added for numerical stability to avoid division by zero\n",
        "\tepsilon = 1e-10\n",
        "\n",
        "\t# True Positives (TP): Sum of product of ground truth and predicted saliency\n",
        "\ttp = torch.sum(ground_truth * predicted_saliency)\n",
        "\n",
        "\t# False Positives (FP): Sum of predicted saliency where ground truth is not present\n",
        "\tfp = torch.sum(predicted_saliency * (1 - ground_truth))\n",
        "\n",
        "\t# True Negatives (TN): Sum of the inverse of ground truth and predicted saliency\n",
        "\ttn = torch.sum((1 - ground_truth) * (1 - predicted_saliency))\n",
        "\n",
        "\t# False Negatives (FN): Sum of ground truth where predicted saliency is not present\n",
        "\tfn = torch.sum(ground_truth * (1 - predicted_saliency))\n",
        "\n",
        "\t# Precision\n",
        "\tprecision = (tp + epsilon) / (tp + fp + epsilon)\n",
        "\n",
        "\t# Recall\n",
        "\trecall = (tp + epsilon) / (tp + fn + epsilon)\n",
        "\n",
        "\t# F1 Score\n",
        "\tf1 = (2 * precision * recall + epsilon) / (precision + recall + epsilon)\n",
        "\n",
        "\treturn precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jlMFJvAO7dqS",
        "outputId": "d67e321d-bf82-453b-f1fc-a68a8151203e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231229_150936-gwj701wo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jessicamarycooper/proxy_benchmark_new/runs/gwj701wo' target=\"_blank\">snowy-paper-26</a></strong> to <a href='https://wandb.ai/jessicamarycooper/proxy_benchmark_new' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jessicamarycooper/proxy_benchmark_new' target=\"_blank\">https://wandb.ai/jessicamarycooper/proxy_benchmark_new</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jessicamarycooper/proxy_benchmark_new/runs/gwj701wo' target=\"_blank\">https://wandb.ai/jessicamarycooper/proxy_benchmark_new/runs/gwj701wo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coverage [0.1        0.10351759 0.10703518 0.11055276 0.11407035 0.11758794\n",
            " 0.12110553 0.12462312 0.1281407  0.13165829 0.13517588 0.13869347\n",
            " 0.14221106 0.14572864 0.14924623 0.15276382 0.15628141 0.15979899\n",
            " 0.16331658 0.16683417 0.17035176 0.17386935 0.17738693 0.18090452\n",
            " 0.18442211 0.1879397  0.19145729 0.19497487 0.19849246 0.20201005\n",
            " 0.20552764 0.20904523 0.21256281 0.2160804  0.21959799 0.22311558\n",
            " 0.22663317 0.23015075 0.23366834 0.23718593 0.24070352 0.24422111\n",
            " 0.24773869 0.25125628 0.25477387 0.25829146 0.26180905 0.26532663\n",
            " 0.26884422 0.27236181 0.2758794  0.27939698 0.28291457 0.28643216\n",
            " 0.28994975 0.29346734 0.29698492 0.30050251 0.3040201  0.30753769\n",
            " 0.31105528 0.31457286 0.31809045 0.32160804 0.32512563 0.32864322\n",
            " 0.3321608  0.33567839 0.33919598 0.34271357 0.34623116 0.34974874\n",
            " 0.35326633 0.35678392 0.36030151 0.3638191  0.36733668 0.37085427\n",
            " 0.37437186 0.37788945 0.38140704 0.38492462 0.38844221 0.3919598\n",
            " 0.39547739 0.39899497 0.40251256 0.40603015 0.40954774 0.41306533\n",
            " 0.41658291 0.4201005  0.42361809 0.42713568 0.43065327 0.43417085\n",
            " 0.43768844 0.44120603 0.44472362 0.44824121 0.45175879 0.45527638\n",
            " 0.45879397 0.46231156 0.46582915 0.46934673 0.47286432 0.47638191\n",
            " 0.4798995  0.48341709 0.48693467 0.49045226 0.49396985 0.49748744\n",
            " 0.50100503 0.50452261 0.5080402  0.51155779 0.51507538 0.51859296\n",
            " 0.52211055 0.52562814 0.52914573 0.53266332 0.5361809  0.53969849\n",
            " 0.54321608 0.54673367 0.55025126 0.55376884 0.55728643 0.56080402\n",
            " 0.56432161 0.5678392  0.57135678 0.57487437 0.57839196 0.58190955\n",
            " 0.58542714 0.58894472 0.59246231 0.5959799  0.59949749 0.60301508\n",
            " 0.60653266 0.61005025 0.61356784 0.61708543 0.62060302 0.6241206\n",
            " 0.62763819 0.63115578 0.63467337 0.63819095 0.64170854 0.64522613\n",
            " 0.64874372 0.65226131 0.65577889 0.65929648 0.66281407 0.66633166\n",
            " 0.66984925 0.67336683 0.67688442 0.68040201 0.6839196  0.68743719\n",
            " 0.69095477 0.69447236 0.69798995 0.70150754 0.70502513 0.70854271\n",
            " 0.7120603  0.71557789 0.71909548 0.72261307 0.72613065 0.72964824\n",
            " 0.73316583 0.73668342 0.74020101 0.74371859 0.74723618 0.75075377\n",
            " 0.75427136 0.75778894 0.76130653 0.76482412 0.76834171 0.7718593\n",
            " 0.77537688 0.77889447 0.78241206 0.78592965 0.78944724 0.79296482\n",
            " 0.79648241 0.8       ]\n",
            "region counts range(1, 6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['rise', 0.4961156219999907, 0.009646045975387096, 1, tensor(0.0806, device='cuda:0'), tensor(0.0221, device='cuda:0'), tensor(0.9583, device='cuda:0'), tensor(0.1008, device='cuda:0'), tensor(0.9278, device='cuda:0'), tensor(0.1818, device='cuda:0')]\n",
            "\n",
            "Believe the HiPe!\n",
            "Num cells: 4\n",
            "Max depth: 4\n",
            "Depth: 1, 28 x 28 Cell Dim\n",
            "Threshold: 0.0\n",
            "Range 0.0 to 0.0\n",
            "Selected 81 masks at depth 1\n",
            "Masks: 81\n",
            "Depth: 2, 14 x 14 Cell Dim\n",
            "Threshold: 814.0\n",
            "Range 0.0 to 1628.0\n",
            "Selected 21 masks at depth 2\n",
            "Masks: 21\n",
            "Depth: 3, 7 x 7 Cell Dim\n",
            "Threshold: 1462.0\n",
            "Range 0.0 to 2924.0\n",
            "Selected 45 masks at depth 3\n",
            "Masks: 45\n",
            "Used 147 masks in total.\n",
            "['hipe', 0.19320235899999716, 0.009646045975387096, 1, tensor(0.0265, device='cuda:0'), tensor(0.0096, device='cuda:0'), tensor(0.9807, device='cuda:0'), tensor(0.2464, device='cuda:0'), tensor(0.8483, device='cuda:0'), tensor(0.3819, device='cuda:0')]\n",
            "['random', 0.0004948110000100314, 0.009646045975387096, 1, tensor(0.5000, device='cuda:0'), tensor(0.3332, device='cuda:0'), tensor(-0.0001, device='cuda:0'), tensor(0.0097, device='cuda:0'), tensor(0.5052, device='cuda:0'), tensor(0.0191, device='cuda:0')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "1it [00:04,  4.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['extremal_perturbation', 3.768780879000019, 0.009646045975387096, 1, tensor(0.0789, device='cuda:0'), tensor(0.0418, device='cuda:0'), tensor(0.9126, device='cuda:0'), tensor(0.0959, device='cuda:0'), tensor(0.8524, device='cuda:0'), tensor(0.1724, device='cuda:0')]\n",
            "['rise', 0.4683553059999781, 0.004823022987693548, 2, tensor(0.1582, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.8743, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.9158, device='cuda:0'), tensor(0.0529, device='cuda:0')]\n",
            "\n",
            "Believe the HiPe!\n",
            "Num cells: 4\n",
            "Max depth: 4\n",
            "Depth: 1, 28 x 28 Cell Dim\n",
            "Threshold: 0.0\n",
            "Range 0.0 to 0.0\n",
            "Selected 81 masks at depth 1\n",
            "Masks: 81\n",
            "Depth: 2, 14 x 14 Cell Dim\n",
            "Threshold: 242.0\n",
            "Range 0.0 to 484.0\n",
            "Selected 42 masks at depth 2\n",
            "Masks: 42\n",
            "Depth: 3, 7 x 7 Cell Dim\n",
            "Threshold: 484.0\n",
            "Range 0.0 to 968.0\n",
            "Selected 62 masks at depth 3\n",
            "Masks: 62\n",
            "Used 185 masks in total.\n",
            "['hipe', 0.18731156100000135, 0.004823022987693548, 2, tensor(0.0518, device='cuda:0'), tensor(0.0175, device='cuda:0'), tensor(0.9649, device='cuda:0'), tensor(0.0775, device='cuda:0'), tensor(0.8921, device='cuda:0'), tensor(0.1426, device='cuda:0')]\n",
            "['random', 0.00047079799998073213, 0.004823022987693548, 2, tensor(0.5011, device='cuda:0'), tensor(0.3348, device='cuda:0'), tensor(-0.0037, device='cuda:0'), tensor(0.0050, device='cuda:0'), tensor(0.5205, device='cuda:0'), tensor(0.0099, device='cuda:0')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r2it [00:08,  4.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['extremal_perturbation', 3.447236607000036, 0.004823022987693548, 2, tensor(0.1427, device='cuda:0'), tensor(0.0731, device='cuda:0'), tensor(0.8412, device='cuda:0'), tensor(0.0313, device='cuda:0'), tensor(0.9543, device='cuda:0'), tensor(0.0606, device='cuda:0')]\n",
            "['rise', 0.46985200900002155, 0.0029296875, 3, tensor(0.2667, device='cuda:0'), tensor(0.1186, device='cuda:0'), tensor(0.7309, device='cuda:0'), tensor(0.0106, device='cuda:0'), tensor(0.9703, device='cuda:0'), tensor(0.0209, device='cuda:0')]\n",
            "\n",
            "Believe the HiPe!\n",
            "Num cells: 4\n",
            "Max depth: 4\n",
            "Depth: 1, 28 x 28 Cell Dim\n",
            "Threshold: 0.0\n",
            "Range 0.0 to 0.0\n",
            "Selected 81 masks at depth 1\n",
            "Masks: 81\n",
            "Depth: 2, 14 x 14 Cell Dim\n",
            "Threshold: 98.0\n",
            "Range 0.0 to 196.0\n",
            "Selected 92 masks at depth 2\n",
            "Masks: 92\n",
            "Depth: 3, 7 x 7 Cell Dim\n",
            "Threshold: 196.0\n",
            "Range 0.0 to 392.0\n",
            "Selected 87 masks at depth 3\n",
            "Masks: 87\n",
            "Used 260 masks in total.\n",
            "['hipe', 0.1878767370000105, 0.0029296875, 3, tensor(0.0800, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.9434, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.9451, device='cuda:0'), tensor(0.0648, device='cuda:0')]\n",
            "['random', 0.0004909659999725591, 0.0029296875, 3, tensor(0.5011, device='cuda:0'), tensor(0.3344, device='cuda:0'), tensor(-0.0038, device='cuda:0'), tensor(0.0030, device='cuda:0'), tensor(0.5139, device='cuda:0'), tensor(0.0060, device='cuda:0')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r3it [00:12,  4.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['extremal_perturbation', 3.416011835000006, 0.0029296875, 3, tensor(0.1827, device='cuda:0'), tensor(0.0837, device='cuda:0'), tensor(0.8165, device='cuda:0'), tensor(0.0130, device='cuda:0'), tensor(0.8165, device='cuda:0'), tensor(0.0255, device='cuda:0')]\n",
            "['rise', 0.47692245500002173, 0.001992984674870968, 4, tensor(0.2612, device='cuda:0'), tensor(0.1203, device='cuda:0'), tensor(0.7228, device='cuda:0'), tensor(0.0066, device='cuda:0'), tensor(0.8671, device='cuda:0'), tensor(0.0131, device='cuda:0')]\n",
            "\n",
            "Believe the HiPe!\n",
            "Num cells: 4\n",
            "Max depth: 4\n",
            "Depth: 1, 28 x 28 Cell Dim\n",
            "Threshold: 0.0\n",
            "Range 0.0 to 0.0\n",
            "Selected 81 masks at depth 1\n",
            "Masks: 81\n",
            "Depth: 2, 14 x 14 Cell Dim\n",
            "Threshold: 62.5\n",
            "Range 0.0 to 125.0\n",
            "Selected 55 masks at depth 2\n",
            "Masks: 55\n",
            "Depth: 3, 7 x 7 Cell Dim\n",
            "Threshold: 112.5\n",
            "Range 0.0 to 225.0\n",
            "Selected 118 masks at depth 3\n",
            "Masks: 118\n",
            "Used 254 masks in total.\n",
            "['hipe', 0.18925471800002924, 0.001992984674870968, 4, tensor(0.0962, device='cuda:0'), tensor(0.0377, device='cuda:0'), tensor(0.9227, device='cuda:0'), tensor(0.0191, device='cuda:0'), tensor(0.9413, device='cuda:0'), tensor(0.0375, device='cuda:0')]\n",
            "['random', 0.0005019550000042727, 0.001992984674870968, 4, tensor(0.4986, device='cuda:0'), tensor(0.3322, device='cuda:0'), tensor(0.0047, device='cuda:0'), tensor(0.0018, device='cuda:0'), tensor(0.4460, device='cuda:0'), tensor(0.0036, device='cuda:0')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r4it [00:16,  3.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['extremal_perturbation', 3.4564528760000144, 0.001992984674870968, 4, tensor(0.1727, device='cuda:0'), tensor(0.0960, device='cuda:0'), tensor(0.7862, device='cuda:0'), tensor(0.0090, device='cuda:0'), tensor(0.7831, device='cuda:0'), tensor(0.0178, device='cuda:0')]\n",
            "['rise', 0.4826404860000366, 0.0015943878097459674, 5, tensor(0.3278, device='cuda:0'), tensor(0.1781, device='cuda:0'), tensor(0.5437, device='cuda:0'), tensor(0.0047, device='cuda:0'), tensor(0.9692, device='cuda:0'), tensor(0.0093, device='cuda:0')]\n",
            "\n",
            "Believe the HiPe!\n",
            "Num cells: 4\n",
            "Max depth: 4\n",
            "Depth: 1, 28 x 28 Cell Dim\n",
            "Threshold: 0.0\n",
            "Range 0.0 to 0.0\n",
            "Selected 81 masks at depth 1\n",
            "Masks: 81\n",
            "Depth: 2, 14 x 14 Cell Dim\n",
            "Threshold: 36.0\n",
            "Range 0.0 to 72.0\n",
            "Selected 74 masks at depth 2\n",
            "Masks: 74\n",
            "Depth: 3, 7 x 7 Cell Dim\n",
            "Threshold: 62.0\n",
            "Range 0.0 to 124.0\n",
            "Selected 173 masks at depth 3\n",
            "Masks: 173\n",
            "Used 328 masks in total.\n",
            "['hipe', 0.1987070870000025, 0.0015943878097459674, 5, tensor(0.1243, device='cuda:0'), tensor(0.0504, device='cuda:0'), tensor(0.8954, device='cuda:0'), tensor(0.0110, device='cuda:0'), tensor(0.8689, device='cuda:0'), tensor(0.0218, device='cuda:0')]\n",
            "['random', 0.00046257500002866436, 0.0015943878097459674, 5, tensor(0.4991, device='cuda:0'), tensor(0.3326, device='cuda:0'), tensor(0.0031, device='cuda:0'), tensor(0.0018, device='cuda:0'), tensor(0.5746, device='cuda:0'), tensor(0.0037, device='cuda:0')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r5it [00:20,  3.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['extremal_perturbation', 3.4454264780000017, 0.0015943878097459674, 5, tensor(0.1919, device='cuda:0'), tensor(0.0997, device='cuda:0'), tensor(0.7757, device='cuda:0'), tensor(0.0056, device='cuda:0'), tensor(0.6752, device='cuda:0'), tensor(0.0111, device='cuda:0')]\n",
            "['rise', 0.46680587299999843, 0.01054288912564516, 1, tensor(0.0940, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.9438, device='cuda:0'), tensor(0.0941, device='cuda:0'), tensor(0.9176, device='cuda:0'), tensor(0.1707, device='cuda:0')]\n",
            "\n",
            "Believe the HiPe!\n",
            "Num cells: 4\n",
            "Max depth: 4\n",
            "Depth: 1, 28 x 28 Cell Dim\n",
            "Threshold: 0.0\n",
            "Range 0.0 to 0.0\n",
            "Selected 81 masks at depth 1\n",
            "Masks: 81\n",
            "Depth: 2, 14 x 14 Cell Dim\n",
            "Threshold: 877.5\n",
            "Range 0.0 to 1755.0\n",
            "Selected 21 masks at depth 2\n",
            "Masks: 21\n",
            "Depth: 3, 7 x 7 Cell Dim\n",
            "Threshold: 1562.0\n",
            "Range 0.0 to 3124.0\n",
            "Selected 41 masks at depth 3\n",
            "Masks: 41\n",
            "Used 143 masks in total.\n",
            "['hipe', 0.18201320200000737, 0.01054288912564516, 1, tensor(0.0375, device='cuda:0'), tensor(0.0124, device='cuda:0'), tensor(0.9753, device='cuda:0'), tensor(0.1955, device='cuda:0'), tensor(0.8224, device='cuda:0'), tensor(0.3160, device='cuda:0')]\n",
            "['random', 0.0005022340000095937, 0.01054288912564516, 1, tensor(0.5017, device='cuda:0'), tensor(0.3348, device='cuda:0'), tensor(-0.0060, device='cuda:0'), tensor(0.0104, device='cuda:0'), tensor(0.4950, device='cuda:0'), tensor(0.0204, device='cuda:0')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r6it [00:24,  3.91s/it]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "log_imgs = True\n",
        "synthetic = True\n",
        "dim_x, dim_y = 224,224\n",
        "i_dim_x, i_dim_y = 224,224\n",
        "\n",
        "methods = ['rise', 'hipe', 'random', 'extremal_perturbation']\n",
        "\n",
        "num_samples=1000\n",
        "min_coverage=0.1\n",
        "max_coverage=0.8\n",
        "max_salient_regions=5\n",
        "random_sal_val=False\n",
        "\n",
        "config = {\"log_imgs\":log_imgs,\"synthetic\":synthetic, \"synthetic_dim\":(dim_x, dim_y),\"input_dim\":(i_dim_x, i_dim_y), \"num_samples\":num_samples, \"min_coverage\":min_coverage, \"max_coverage\":max_coverage, \"max_salient_regions\":max_salient_regions, \"random_sal_val\":random_sal_val}\n",
        "\n",
        "run = wandb.init(project='proxy_benchmark_new', entity=\"jessicamarycooper\", reinit=True, config=config)\n",
        "columns=['method', 'time', 'salient region size', 'number of salient regions', 'mae', 'mse', 'cos', 'precision', 'recall', 'f1']\n",
        "if log_imgs:\n",
        "\tcolumns.extend(['target', 'output'])\n",
        "\n",
        "table = wandb.Table(columns=columns)\n",
        "\n",
        "\n",
        "if synthetic:\n",
        "\tdata = SyntheticDataset(num_samples=num_samples, dim=(dim_x, dim_y), min_coverage=min_coverage, max_coverage=max_coverage, max_salient_regions=max_salient_regions, random_sal_val=random_sal_val)\n",
        "else:\n",
        "\tdata = get_dataset(name='coco', subset='val2014', download=True, limiter=num_samples, transform=transforms.ToTensor())\n",
        "\n",
        "loader = DataLoader(data, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "data_iterator = iter(loader)\n",
        "\n",
        "device = get_device()\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = ProxyModel(numel=dim_x*dim_y).to(device)\n",
        "model.eval()\n",
        "\n",
        "class_id = 0\n",
        "all_results = []\n",
        "\n",
        "for i, xy in tqdm(enumerate(data_iterator)):\n",
        "\tx, sal_size, sal_num = xy\n",
        "\tx = F.interpolate(x, (i_dim_x, i_dim_y), mode='nearest')\n",
        "\txd, yd = x.shape[-1], x.shape[-2]\n",
        "\txn = normalise(x.to(device))\n",
        "\tif synthetic:\n",
        "\t\ttarget = xn.clone()[0]\n",
        "\telse:\n",
        "\t\ttarget = xn.sum(dim=1)\n",
        "\n",
        "\tfor method in methods:\n",
        "\n",
        "\t\ttic = time.process_time()\n",
        "\n",
        "\t\tif method == 'hipe':\n",
        "\t\t\tsaliency, num_ops = hierarchical_perturbation(model, xn, class_id, resize=(i_dim_x, i_dim_y), perturbation_type='fade')\n",
        "\n",
        "\t\telif method == 'random':\n",
        "\t\t\tsaliency = torch.rand(xn.shape).squeeze(0).to(device)\n",
        "\n",
        "\n",
        "\t\telif method == \"rise\":\n",
        "\t\t\trise_saliency = rise(model, xn.clone().detach(), resize=(i_dim_x, i_dim_y))\n",
        "\t\t\tsaliency = rise_saliency[:, class_id, :, :]\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tareas = [0.018, 0.025, 0.05, 0.1]\n",
        "\n",
        "\t\t\tmask, energy = elp.extremal_perturbation(model,\n",
        "\t\t\t\t\txn,\n",
        "\t\t\t\t\tclass_id,\n",
        "\t\t\t\t\tareas=areas,\n",
        "\t\t\t\t\tnum_levels=8,\n",
        "\t\t\t\t\tstep=7,\n",
        "\t\t\t\t\tsigma=7 * 3,\n",
        "\t\t\t\t\tmax_iter=800,\n",
        "\t\t\t\t\tdebug=False,\n",
        "\t\t\t\t\tjitter=True,\n",
        "\t\t\t\t\tsmooth=0.09,\n",
        "\t\t\t\t\tresize=(i_dim_x, i_dim_y),\n",
        "\t\t\t\t\tperturbation='fade',\n",
        "\t\t\t\t\treward_func=elp.simple_reward,\n",
        "\t\t\t\t\tvariant=elp.PRESERVE_VARIANT, )\n",
        "\t\t\tsaliency = mask.sum(dim=0)\n",
        "\n",
        "\t\ttoc = time.process_time()\n",
        "\t\toutput = normalise(saliency.clone())\n",
        "\n",
        "\t\tmae = torch.abs(output-target).mean()\n",
        "\t\tmse = ((output-target)**2).mean()\n",
        "\t\tcos = F.cosine_similarity(output.view(-1).unsqueeze(0)-0.5, target.view(-1).unsqueeze(0)-0.5).mean()\n",
        "\n",
        "\t\tprec, rec, f1 = calculate_precision_recall_f1(target, output)\n",
        "\n",
        "\t\tdata=[method, toc - tic, sal_size.item(), sal_num.item(), mae, mse, cos, prec, rec, f1]\n",
        "\n",
        "\t\tif log_imgs:\n",
        "\t\t\tprint(data)\n",
        "\t\t\tdata.extend([wandb.Image(target, caption=f'{output.sum()}'), wandb.Image(output, caption=f'{output.sum()}')])\n",
        "\t\ttable.add_data(*data)\n",
        "wandb.log({'Table':table})\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RREY6QogCUT9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
